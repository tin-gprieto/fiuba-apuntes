- **[DAH] — cap. 4**: _Concurrency and Threads_
- **[ARP] — cap. 26**: _Concurrency: An Introduction_
- **[ARP] — cap. 27**: _Interlude: Thread API_
- **[ARP] — cap. 28**: _Locks_
- **[ARP] — cap. 32**: _Common Concurrency Problems_

-------------------------------------------------------------

**El mundo de la concurrencia se refiere a un conjunto de actividades que pueden suceder en el mismo tiempo.** Anderson-Dahlin pag. 129.

!= Programación Secuencial

El concepto clave a la hora de escribir un programa concurrente es escribirlo como una secuencia de _streams de ejecución_ o _threads_. 

Un _thread_ es una **secuencia de ejecución atómica** que representa una **tarea planificable de ejecución**. Estos interactuan y comporten datos en una manera muy precisa entre si.

- **Secuencia de ejecución atómica**: Cada thread ejecuta una secuencia de instrucciones como lo hace un bloque de código en el modelo de programación secuencial.
    
- **Tarea planificable de ejecución**: El sistema operativo tiene injerencia sobre el mismo en cualquier momento y puede ejecutarlo, suspenderlo y continuarlo cuando él desee.

## Diferencias con los procesos

**Proceso**: Un programa en ejecución con derechos restringidos

**Thread**: Un secuencia independiente de instrucciones ejecutandose dentro de un programa

Los **threads**:
    
- Por defecto comparten memoria
	
- Por defecto comparten los descriptores de archivos
	
- Por defecto comparten el contexto del file system
	
- Por defecto comparten el manejo de señales
    
Los **Procesos**
    
- Por defecto **no** comparten memoria
	
- Por defecto **no** comparten los descriptores de archivos
	
- Por defecto **no** comparten el contexto del filsystem
	
- Por defecto **no** comparten el manejo de señales

### Tipos de threads

1. **One thread per process**: un proceso con una única secuencia de instrucciones ejecutándose de inicio a fin.
2. **Many thread per process**: un programa es visto como threads ejecutándose dentro de un proceso con derechos restringidos.
3. **Many single-threaded processes**: limitación de algunos sistemas operativos que permitían varios procesos, pero cada uno con un único thread, lo que implica que puede haber varios threads ejecutándose en kernel model.
4. **Many kernel threads**: para aprovechar recursos, también el kernel puede ejecutar varios threads en kernel mode.

## Thread Scheduler

En caso de trabajar con un único procesador se necesita un planificador de thread. Como el cambio entre threads es _trasparente_, es decir que el propio SO determina cuando un thread se suspende y cuando no.

Los threads proveen un modelo de ejecución en el cual **cada thread corre en un procesador virtual dedicado (exclusivo) con una velocidad variable e impredecible** Anderson-Dahlin, pag 138.

**Formas de relacionarse**:

1. _Multi-threading Cooperativo_: no hay interrupción a menos que se solicite.
    
2. _Multi-threading Preemptivo_: Es el más usado en la actualidad. Consiste en que un threads en estado de _running_ puede ser movido en cualquier momento.

## API de threads

(...)

## Estructura y Ciclo de Vida de un thread

Para lograr una ilusión creíble de que cada thread cuenta con su propio procesador (virtualization), hace falta que la abstracción contemple 2 tipo de estados:

 - Estado **per thread** -> **Thread Control Block (TCB)**
 - Estado **compartido** entre varios threads -> **Shared State**

### Thread Control Block (TCB)

Este almacena:
- Estado del computo que debe realizar el thread
- Puntero al stack del thread
- Una copia de sus registros en el procesador


### Shared State

Información compartida por varios threads:

- El código
- Variables globales
- Variable del Heap

## Estados de un thread

- **Init**: Se esta inicializando el TCB y se reserva el espacio de memoria necesario
- **Ready**: Se encuentra en una _ready list_ de threads listos a ser ejecutados
- **Running**: thread que se esta ejecutando. Puede pasar de nuevo a _ready_ si el scheduler lo desaloja del CPU (guardando el valor de sus registros) o si el mismo thread abandona la ejecución voluntariamente (_thread_yield_)
- **Waiting**: Se encuentra en _waiting list_ esperando a que un determinado evento suceda
- **Finishing**: Nunca podrá volver a ser ejecutado (se encuentra dentro de _finnished list_)

## Sincronizacion

A la hora de manejar un conjunto de _threads_ nos podemos encontrar con dos escenarios:

1. Un conjunto de threads _independientes_ que operan sobre un conjunto de datos completamente separados e independientes.
2. Un conjunto de threads _cooperativos_ que trabajan sobre un mismo set de memoria y datos

Para este ultimo caso, la forma de pensar secuencial no funciona, por lo tanto se debe estructurar el programa para que resulte fácil el razonamiento concurrente y utilizar un conjunto de primitivas estándares para sincronizar el acceso a los recursos compartidos.

### Race Conditions

Una _race condition_ se da cuento el resultado de un programa depende de como se intercalaron las operaciones de los threads, es decir, que thread modifica primero el dato compartido.

### Operaciones atómicas 

Si se utilizan operaciones atómicas, que en assembly no permitan que otras se intercalen, se puede apalear las consecuencias de una intercalación inesperada.

Ej. load y store en 32b son operaciones atómicas (en 64b no)

**Conceptos importantes**

- _safety_ (nada malo va a pasar): el programa nunca termina en estado incorrecto
- _liveness_ (si algo va a pasar tiene que ser bueno): el programa eventualmente esta en un estado correcto.


### Solución locks

Una solución para problemas de race conditions es el _lock_, una variable que permite la sincronizacion mediante **exclusion mutua**.

La idea principal es que un proceso asocia un lock a determinados estados o partes del código y requiere que el thread posea el lock para entrar en ese estado, por lo que solo un thread accede a un recurso compartido a la vez. Es así como se garantiza la atomicidad de las operaciones.

Estados de un lock: _BUSY_ o _FREE_ (default)

Se utiliza la primitiva _obtener()_ para pedir acceso al lock (a la region de exclusion mutua). Mediante la primitiva _dejar()_ se vuelve a liberar el lock 

Un lock debe asegurar :

1. **Exclusión mutua**: como mucho un solo Threads posee el lock a la vez.
    
2. **Progress**: Si nadie posee el lock, y alguien lo quiere … alguno debe poder obtenerlo.
    
3. **Bounded waiting**: Si T quiere acceder al lock y existen varios threads en la misma situación, los demás tienen una cantidad finita (un límite) de posible accesos antes que T lo haga.

La **Sección Crítica** es aquella sección del código fuente que se necesita que se ejecute en forma atómica. Para ello esta sección se encierra dentro de un lock.

## Errores comunes de concurrencia

En **Learning from mistakes: a comprehensive study on real world concurrency bug characteristics** - Shan Lu, Soyeon Park, Eunsoo Seo, and Yuanyuan Zhou, 2008, se definen dos tipos de errores:

1. **Non-deadlock Bugs**
    
2. **Deadlock Bugs**

### Non-Deadlock Bugs

Existen dos marcados errores que no están relacionados con deadlock:

1. **Atomicity violation**: “el deseo de la serialización entre múltiples accesos a memoria es violado” Lu et al.
    ![_images/atomicy_violation.jpg](https://fisop.github.io/apunte/_images/atomicy_violation.jpg)

2. **Order Violation**: “El orden deseado entre accesos a memoria se ha cambiado” Lu et al.
![_images/order_violation.jpg](https://fisop.github.io/apunte/_images/order_violation.jpg) ![_images/order_violation_2.jpg](https://fisop.github.io/apunte/_images/order_violation_2.jpg) ![_images/write_write_order_violation.jpg](https://fisop.github.io/apunte/_images/write_write_order_violation.jpg)


### DeadLock Bugs

**¿Qué es un deadlock?** En concurrencia el concepto de dead lock aparece cuando entre dos o más threads uno obtiene el lock y por algún motivo nunca libera el mismo haciendo que sus compañeros se bloqueen.

#### Condiciones Necesarias para que se dé un DeadLock

Según Coffman, E. G., Elphick, M., & Shoshani, A. (1971). System deadlocks. ACM Computing Surveys (CSUR), 3(2), 67-78. existen cuatro condiciones para que se de un deadlock:

- **Exclusión mutua**: los thread reclama control exclusivo sobre un recurso compartido que necesitan.
    
- **Hold-and-Wait**: un thread mantiene un recurso reservado para sí mismo mientras espera que se de alguna condición.
    
- **No preemption**: los recursos adquiridos no pueden ser desalojados (preempted) por la fuerza.
    
- **Circular wait**: existe una conjunto de threads que de forma circular cada uno reserva uno o mas recursos que son requeridos por el siguiente en la cadena.